{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Pumas-AI Data Wrangling Workshop","text":"<p>This workshop is an introduction to data wrangling in Julia with a focus on data I/O and <code>DataFramesMeta.jl</code>. We will cover the following topics: </p> <ul> <li> <p>Reading and writing data:</p> <ul> <li>CSV files</li> <li>Excel (<code>.xlsx</code>) files</li> <li>SAS (<code>.sasb7dat</code> and <code>.xpt</code>)</li> </ul> </li> <li> <p>Select:</p> <ul> <li>Selecting specific columns and rows using <code>@select</code> and <code>@subset</code> macros</li> </ul> </li> <li> <p>Transform:</p> <ul> <li>Applying transformations to one or more columns using the <code>@transform</code> macro</li> </ul> </li> <li> <p>Grouping and combining:</p> <ul> <li>Grouping data using the <code>groupby</code> function</li> <li>Combining groups and summarizing data using the <code>@combine</code> and <code>@by</code> macros</li> </ul> </li> <li> <p>Chaining:</p> <ul> <li>Perform all data wrangling operations in a single block using the <code>@chain</code> macro</li> </ul> </li> </ul> <p>Prerequisites</p> <p>We recommend users being familiar with Julia syntax, especially variables and types.</p> <p>The formal requirements are the Julia Syntax Workshop and its pre-requisites.</p>"},{"location":"#schedule","title":"Schedule","text":"Time (HH:MM) Activity Description 00:00 Setup Download files required for the workshop 00:25 Reading and writing data Showcase <code>01-files.jl</code> 00:40 Select Showcase <code>02-select_subset.jl</code> 00:50 Transform Showcase <code>03-transform.jl</code> 01:00 Grouping and combining Showcase <code>04-grouping.jl</code> 01:05 Chaining Showcase <code>05-chaining.jl</code> 01:15 Closing remarks See if there are any questions and feedback"},{"location":"#get-in-touch","title":"Get in touch","text":"<p>If you have any suggestions or want to get in touch with our education team, please send an email to training@pumas.ai.</p>"},{"location":"#authors","title":"Authors","text":"<ul> <li>Juan Jos\u00e9 Gonz\u00e1lez Oneto - j.oneto@pumas.ai</li> </ul>"},{"location":"#license","title":"License","text":"<p>This content is licensed under Creative Commons Attribution-ShareAlike 4.0 International.</p> <p></p>"},{"location":"code_of_conduct/","title":"Code of Conduct for Pumas-AI Data Wrangling Workshop","text":"<p>At Pumas-AI we are committed to creating a friendly and respectful place for learning, teaching and contributing. All participants in our events and communications are expected to show respect and courtesy to others. To make clear what is expected, everyone participating in Pumas-AI activities is required to conform to the Code of Conduct.</p> <p>Pumas-AI is dedicated to providing a welcoming and supportive environment for all people, regardless of background or identity. As such, we do not tolerate behaviour that is disrespectful to our instructors or learners or that excludes, intimidates, or causes discomfort to others. We do not tolerate discrimination or harassment based on characteristics that include, but are not limited to, gender identity and expression, sexual orientation, disability, physical appearance, body size, citizenship, nationality, ethnic or social origin, pregnancy, familial status, veteran status, genetic information, religion or belief (or lack thereof), membership of a national minority, property, age, education, socio-economic status, technical choices, and experience level.</p>"},{"location":"code_of_conduct/#expected-behaviour","title":"Expected Behaviour","text":"<p>All participants in our events and communications are expected to show respect and courtesy to others. All interactions should be professional regardless of platform: either online or in-person. In order to foster a positive and professional learning environment we encourage the following kinds of behaviours in all Pumas-AI events and platforms:</p> <ul> <li>Use welcoming and inclusive language</li> <li>Be respectful of different viewpoints and experiences</li> <li>Gracefully accept constructive criticism</li> <li>Focus on what is best for the community</li> <li>Show courtesy and respect towards other community members</li> </ul>"},{"location":"code_of_conduct/#unacceptable-behaviour","title":"Unacceptable Behaviour","text":"<p>Examples of unacceptable behaviour by participants at any Pumas-AI event/platform include:</p> <ul> <li>written or verbal comments which have the effect of excluding people on the basis of membership of any specific group</li> <li>causing someone to fear for their safety, such as through stalking, following, or intimidation</li> <li>violent threats or language directed against another person</li> <li>the display of sexual or violent images</li> <li>unwelcome sexual attention</li> <li>nonconsensual or unwelcome physical contact</li> <li>sustained disruption of talks, events or communications</li> <li>insults or put downs</li> <li>sexist, racist, homophobic, transphobic, ableist, or exclusionary jokes</li> <li>excessive swearing</li> <li>incitement to violence, suicide, or self-harm</li> <li>continuing to initiate interaction (including photography or recording) with someone after being asked to stop</li> <li>publication of private communication without consent</li> </ul>"},{"location":"code_of_conduct/#consequences-of-unacceptable-behaviour","title":"Consequences of Unacceptable Behaviour","text":"<p>Participants who are asked to stop any inappropriate behaviour are expected to comply immediately. This applies to any Pumas-AI events and platforms, either online or in-person. If a participant engages in behaviour that violates this code of conduct, the organisers may warn the offender, ask them to leave the event or platform (without refund, if applicable), or engage with Pumas-AI representatives to investigate the Code of Conduct violation and impose appropriate sanctions.</p>"},{"location":"code_of_conduct/#get-in-touch","title":"Get in touch","text":"<p>If you have any suggestions or want to get in touch with our education team, please send an email to training@pumas.ai.</p>"},{"location":"code_of_conduct/#license","title":"License","text":"<p>This content is licensed under Creative Commons Attribution-ShareAlike 4.0 Internacional.</p> <p></p>"},{"location":"contribute/","title":"How to Contribute","text":"<p>If you want to contribute to this workshop, please open a pull request at <code>PumasAI-Labs/Data-Wrangling</code>.</p> <p>By submitting a pull request, you are in accordance that your contribution will be licensed under Creative Commons Attribution-ShareAlike 4.0 International.</p> <p>Once your pull request is approved and merged, you'll be acknowledged as one of the authors in the workshop site and GitHub repository.</p>"},{"location":"instructors/","title":"Instructor's Notes for Pumas-AI Data Wrangling Workshop","text":"<p>Start with <code>01-files.jl</code>, which covers file handling in Julia. Begin by emphasizing the significance of working in the correct  directory before reading or writing data and how omitting this consideration could lead to errors. Show how to use the <code>pwd</code> function to verify the present  working directory and how to use <code>cd</code> to navigate to another directory if needed. Some users might find it more convenient to right click on the file and use the <code>Julia: Change to This Directory</code> option, which will automatically move the Julia REPL to the directory containing the selected file. If there are  participants who know how to use shell commands, you can mention how to enter the <code>shell&gt;</code> mode in the REPL by typing <code>;</code>. Next, focus on the CSV format. Make  sure to highlight the importance of this format and provide an in-depth explanation of how to read and write CSV files to the present working directory and  to a different data folder. One of the examples provided involves using the <code>rename</code> function, so make sure to go over how it can be used to change column names  in a <code>DataFrame</code>.</p> <p>Next, go over the use of the <code>XLSX.jl</code> package to read Excel files. Start by explaining how to read an Excel file using <code>XLSX.readtable</code>, emphasizing that it is  required to provide the sheet name as an argument and that most of the time, you will want to convert the output from <code>XLSX.readtable</code> to a <code>DataFrame</code>.  There may be questions about what to do if the user doesn't know the sheet names, which you can address by showing how to use <code>XLSX.readxlsx</code> and <code>XLSX.sheetnames</code> to obtain a list of sheet names in an Excel file. You might also find it useful to demonstrate how to open an Excel file inside of  VS Code (using the Office Viewer extension, which is installed by default in JuliaHub). Once you have covered how to read files, show how to write files. Make  sure to mention that <code>XLSX.jl</code> will not override an existing file like <code>CSV.jl</code> would. Instead, you will get an error if you try to create a file that  already exists.</p> <p>The last topic for <code>01-files.jl</code> is SAS files (<code>.sasb7dat</code> and <code>.xpt</code>), which can be read using the <code>readstat</code> function from the <code>ReadStatTables.jl</code> package.  However, note that the current version of <code>ReadStatTables.jl</code> only supports reading files, and write support is still experimental.</p> <p>Next, go over the contents of <code>02-select_subset.jl</code>. First, discuss the <code>names</code> function, which allows us to obtain a <code>Vector</code> containing all the column  names of a <code>DataFrame</code>, which could be useful when working with <code>DataFrames</code> that have a large number of columns. After that, show the different alternatives that there are to retrieve the contents of a single column (dot syntax such as <code>DataFrame.column_name</code> and indexing). Participants might be curious about the difference between these two methods. If that is the case, you can explain that the dot syntax is simpler and more convenient to type, but that indexing is more  flexible and powerful. Additionally, some users could find the indexing syntax more intuitive, even if it is more verbose. When going over indexing, make sure to explain the difference between using <code>!</code> and using <code>:</code> to retrieve all rows from a column (<code>!</code> returns the column, while <code>:</code> returns a copy of it).</p> <p>Afterward, showcase how to select specific columns from a <code>DataFrame</code> using the <code>@select</code> macro provided by <code>DataFramesMeta.jl</code>. This will be the first time in the workshop in which attendees will use <code>DataFramesMeta.jl</code>, so you can take this opportunity to provide a brief overview of the package and its  importance. Make sure to mention that <code>DataFramesMeta.jl</code> imports the contents of <code>DataFrames.jl</code>, so it's not necessary to import <code>DataFrames.jl</code> if <code>DataFramesMeta.jl</code> has already been imported. Lastly, demonstrate the use of the <code>Not</code> operator as a means to specify the columns that we don't want to select, which might be useful in cases where there is a large number of columns and we want to select most of them.</p> <p>Finally, cover the <code>@[r]subset</code> macro, which enables us to filter rows in a <code>DataFrame</code> based on specific conditions. Go over the differences between <code>@subset</code> and <code>@rsubset</code> in detail, as this concept will be used in the scripts that follow. Finish this part of the lesson by going over the common use case of removing rows with <code>missing</code> observations in a specific column.</p> <p>The next script in the workshop is <code>03-transform.jl</code>, which focuses on using the <code>@[r]transform</code> macro to create a new column in a <code>DataFrame</code> or modify an  existing one. Once again, it is important to explain the difference between the column and row versions of the macro (<code>@transform</code> and <code>@rtransform</code>,  respectively) and demonstrate how the latter provides a more convenient way of specifying column transformations whenever possible.</p> <p>After that, introduce the <code>@astable</code> macro, which enables accessing intermediate calculations within a <code>DataFramesMeta.jl</code> macro call. This macro allows performing  operations on multiple columns simultaneously, making it easier to apply complex transformations and computations that would otherwise be challenging to write  and comprehend.</p> <p>Lastly, cover the mutating version of the macros, which allow direct modification of the original <code>DataFrame</code>. Make sure to explain that these macros can be  accessed by appending an exclamation mark (<code>!</code>) at the end of the macro call, such as <code>@[r]transform!</code> or <code>select!</code>. This feature is particularly handy when  there is a need to update or transform data in-place, eliminating the requirement for creating additional copies of the <code>DataFrame</code>.</p> <p>Move on to the <code>04-grouping.jl</code> script. Begin by showing the <code>groupby</code> function, which allows grouping data based on specific columns. If users are curious  about the return values of <code>groupby</code>, you can mention that it returns a <code>GroupedDataFrame</code>, which can be inspected through indexing and manipulated with  <code>transform</code> and <code>select</code> (you can find more details about it in <code>groupby</code>'s documentation). Next,  show the common pattern of using <code>groupby</code> with <code>@combine</code> to apply operations on grouped data and generate aggregated results. Make sure to go over  the examples and cover the cases where one or more columns are used to group data. One of the examples includes the use of the <code>@orderby</code> macro, so take this  opportunity to provide a detailed explanation of how it works.</p> <p>Once participants are comfortable with using <code>groupby</code> and <code>@combine</code>, you can introduce the <code>@by</code> macro, which provides a concise alternative to using  <code>groupby</code> and <code>@combine</code> by streamlining the process of grouping data and applying operations in a single call. Use the example provided in the script to show a  direct comparison between the methods and mention how using <code>@by</code> simplifies the code and enhances readability.</p> <p>The last script of the workshop is <code>05-chaining.jl</code>. This script provides two examples of how to use the <code>@chain</code> macro to perform all data wrangling operations in a single block. Go over the examples and highlight how it can be more convenient than applying all the data wrangling operations separately. Some important points to mention here are that it is not necessary to pass the <code>DataFrame</code> as an argument inside the <code>@chain</code> block, and that it is not restricted to including <code>DataFramesMeta.jl</code> macros (it can also include functions from <code>DataFrames.jl</code> such as <code>rename</code>).</p>"},{"location":"instructors/#get-in-touch","title":"Get in touch","text":"<p>If you have any suggestions or want to get in touch with our education team, please send an email to training@pumas.ai.</p>"},{"location":"instructors/#license","title":"License","text":"<p>This content is licensed under Creative Commons Attribution-ShareAlike 4.0 International.</p> <p></p>"},{"location":"reference/","title":"Reference Sheets for Pumas-AI Data Wrangling Workshop","text":""},{"location":"reference/#key-points","title":"Key Points","text":"<ul> <li>Before reading or writing data, make sure that you are in the correct directory. You can check the present working directory with the <code>pwd</code> function,  and you can navigate to another directory using <code>cd</code>.</li> <li>You can enter the <code>shell&gt;</code> mode in the REPL by typing <code>;</code>, which enables you to execute system shell commands (e.g., <code>pwd</code>, <code>cd</code>, <code>mkdir</code>, etc.).</li> <li>There are various data formats, but CSV is one of the most commonly used formats.</li> <li>To read a CSV file, you can use the <code>CSV.read</code> function, and to create or write a CSV file, you can use the <code>CSV.write</code> function.</li> <li>The <code>CSV.read</code> function takes two arguments: a file path and a sink. In most cases, you will use <code>DataFrame</code> as the sink.</li> <li>The <code>rename</code> function allows you to change the column names of a <code>DataFrame</code>.</li> <li>In some cases, CSV files may not use commas for separation. If that is the case, you can use the <code>delim</code> keyword argument to specify  the character used in your file.</li> <li>In some regions, commas are used to separate decimals instead of dots (e.g., <code>3,14</code> instead of <code>3.14</code>). In such cases, columns containing  <code>Float</code>s will be interpreted as <code>String</code>s. To avoid this, you can use the <code>decimal</code> keyword argument.</li> <li>The <code>XLSX.jl</code> package enables reading and writing of Excel files (<code>.xlsx</code>). To read a file, you can use the <code>XLSX.readtable</code> function, and to write a file,  you can use <code>XLSX.writetable</code>.</li> <li>When using <code>XLSX.readtable</code>, you need to specify the sheet you want to read from since Excel files can have multiple sheets. If you are unsure  about the sheets in the Excel file, you can use <code>XLSX.readxlsx</code> and <code>XLSX.sheetnames</code> to obtain a <code>Vector</code> containing all the sheet names.</li> <li>SAS files (<code>.sasb7dat</code> and <code>.xpt</code>) can be read using the <code>readstat</code> function provided by the <code>ReadStatTables.jl</code> package.</li> <li>Currently, <code>ReadStatTables.jl</code> only supports reading files. Write support is experimental and not fully developed.</li> <li>You can read and write files from different locations by providing the full or relative path instead of just the file name. For more information on  specifying robust and complex file paths, refer to the Filesystem section in the Julia documentation.</li> <li>To obtain a <code>Vector</code> with all the column names of a <code>DataFrame</code>, you can use the <code>names</code> function. This is particularly useful when examining  <code>DataFrame</code>s with a large number of columns.</li> <li><code>DataFramesMeta.jl</code> imports <code>DataFrames.jl</code>, allowing you to import only <code>DataFramesMeta.jl</code> and still have access to the functions from <code>DataFrames.jl</code>.</li> <li>You can select a group of columns from a <code>DataFrame</code> using the <code>@select</code> macro provided by <code>DataFramesMeta.jl</code>.</li> <li>Instead of specifying which columns you want to select, you can specify the columns that you don't want to select using the <code>Not</code> operator, which need to be called with <code>$()</code> (e.g. <code>@select &lt;DataFrame&gt; $(Not(column_name))</code>).</li> <li>You can select the rows in a <code>DataFrame</code> that satisfy a condition using the <code>@[r]subset</code> macro.</li> <li>The row version of a <code>DataFramesMeta.jl</code> macro can be accessed by adding an <code>r</code> before the macro name (e.g., <code>@rsubset</code>, <code>@rtransform</code>, etc.).  These versions are useful as they eliminate the need to broadcast all operations inside the call, but there are cases where it is not possible to do so.</li> <li>To remove rows that have <code>missing</code> values in a column, you can use <code>@rsubset &lt;DataFrame&gt; !ismissing(:column_name)</code>.</li> <li>The <code>@[r]transform</code> macro allows you to create a new column or modify an existing one.</li> <li>The <code>@astable</code> macro enables access to intermediate calculations within a <code>DataFramesMeta.jl</code> macro call and allows operations on multiple columns simultaneously.</li> <li>By appending <code>!</code> at the end of a macro call (e.g., <code>@[r]transform!</code> or <code>select!</code>), you can modify the original <code>DataFrame</code> instead of creating a new one.</li> <li>The <code>groupby</code> function is used to group data in a <code>DataFrame</code> based on specific columns. When used together with <code>@combine</code>, it enables  applying operations on grouped data and generating new aggregated results.</li> <li>The <code>@by</code> macro provides a concise alternative to using <code>groupby</code> and <code>@combine</code>. It allows grouping data and applying operations in a single call.</li> <li>Including <code>length(:column)</code> in a <code>@combine</code> or <code>@by</code> call will return the number of rows in each grouped <code>DataFrame</code> as part of the aggregated results.  The column name used does not affect the results.</li> <li>You can perform all your data wrangling operations in a single block using <code>@chain</code>. This block can include both <code>DataFramesMeta.jl</code> macros and functions  such as <code>rename</code>. Additionally, <code>@chain</code> passes the <code>DataFrame</code> as an argument to every function and macro call. For example, inside a <code>@chain</code> block,  you can write <code>@groupby &lt;column&gt;</code> instead of <code>@groupby &lt;DataFrame&gt; &lt;column&gt;</code>.</li> </ul>"},{"location":"reference/#summary-of-basic-commands","title":"Summary of Basic Commands","text":"Action Command Observations Get the current working directory <code>pwd()</code> Equivalent to running <code>pwd</code> in the shell Change the current working directory <code>cd(&lt;path&gt;)</code> Equivalent to running <code>cd &lt;path&gt;</code> in the shell Enter the <code>shell&gt;</code> mode in the Julia REPL Type <code>;</code> in the REPL Read a CSV file <code>CSV.read(&lt;filepath&gt;, &lt;sink&gt;)</code> The sink argument will be a <code>DataFrame</code> most of the time Write a CSV file <code>CSV.write(&lt;filepath&gt;, &lt;DataFrame&gt;)</code> Change the column names <code>rename(&lt;DataFrame&gt;, &lt;Dict&gt;)</code> or <code>rename(&lt;function&gt;, &lt;DataFrame&gt;)</code> Using the function version can be useful to apply the same type of change to all the columns in the <code>DataFrame</code> Read an Excel file <code>DataFrame(XLSX.readtable(&lt;filepath&gt;, &lt;sheet&gt;))</code> Write an Excel file <code>XLSX.writetable(&lt;filepath&gt;, &lt;DataFrame&gt;)</code> Inspect the sheet names of an Excel file <code>XLSX.readxlsx(&lt;filepath&gt;)</code> and <code>XLSX.sheetnames(&lt;result of readxlsx&gt;)</code> (optional) The result of <code>XLSX.readxlsx</code> will print a table containing the sheet names. You can optionally then run <code>XLSX.sheetnames</code> on the result of <code>readxlsx</code> to get a <code>Vector</code> with all the sheet names Read a SAS file (.sasb7dat and .xpt) <code>DataFrame(readstat(&lt;filepath&gt;))</code> Get the column names of a <code>DataFrame</code> <code>names(&lt;DataFrame&gt;)</code> Get the values from a <code>DataFrame</code>'s column <code>DataFrame.column_name</code>, <code>DataFrame[!, column_name]</code> or <code>DataFrame[:, column_name]</code> The dot syntax is more readable and easier to type, but the indexing syntax could be more intuitive for some users. Using <code>:</code> when indexing returns a copy of the column, while using <code>!</code> returns the original column from the <code>DataFrame</code> (you could use the result of indexing with <code>!</code> to modify the source <code>DataFrame</code>) Select one or more columns from a <code>DataFrame</code> <code>@select &lt;DataFrame&gt; column1 column2 ...</code> Can also be done through indexing, but the <code>@select</code> macro is more convenient and expressive Use the row version of a <code>DataFramesMeta.jl</code> macro <code>@r&lt;macro&gt;</code> (e.g <code>@rsubset</code>, <code>@rtransform</code>, etc.) Filter rows in a <code>DataFrame</code> using a boolean expression <code>@[r]subset &lt;DataFrame&gt; &lt;expression&gt;</code> Determine whether a variable is of <code>Type</code> <code>Missing</code> <code>ismissing(&lt;var&gt;)</code> Can be used with <code>@[r]subset</code> to remove missing values from a <code>DataFrame</code> Create or modify a column <code>@[r]transform &lt;DataFrame&gt; &lt;expression&gt;</code> The expression is written in the assignment form (e.g. <code>:column_name = &lt;column value&gt;</code>). If you want to create a new column, then the assignment should be for a column name that doesn't exist in the <code>DataFrame</code>. If you use an existing column name, <code>@[r]transform</code> will modify that column. Access intermediate calculations and manipulate multiple columns at the same time Include <code>@astable</code> inside a macro call Should be included before the expressions corresponding to the macro call (e.g. <code>@[r]transform &lt;DataFrame&gt; @astable &lt;expression&gt;</code>) Use the in-place (mutating) version of a macro Add <code>!</code> add the end (e.g <code>@[r]transform!</code>) This will apply the changes to the original <code>DataFrame</code>, instead of creating a new one Group data in a <code>DataFrame</code> according to one or more columns <code>groupby(&lt;DataFrame&gt;, &lt;columns&gt;)</code> If you want to use more than one column, <code>&lt;columns&gt;</code> should be a <code>Vector</code> of column names Apply operations on a grouped <code>DataFrame</code> to create aggregated results <code>@combine &lt;DataFrame&gt; &lt;expressions&gt;</code> Group a <code>DataFrame</code> and apply operations to create aggregated results <code>@by &lt;DataFrame&gt; &lt;grouping columns&gt; &lt;expressions&gt;</code> It is equivalent to <code>groupby(&lt;DataFrame&gt;, &lt;grouping columns&gt;)</code> and then <code>@combine &lt;grouped DataFrame&gt; &lt;expessions&gt;</code> Perform all data wrangling operations in a single block <code>@chain &lt;DataFrame&gt; &lt;block&gt;</code> It is not necessary to pass the <code>DataFrame</code> as an argument to the macros and functions used inside of the <code>@chain</code> block"},{"location":"reference/#glossary","title":"Glossary","text":"CSV files <p>CSV stands for Comma-Separated Values. It is a popular file format that uses lines to represent rows (observations) and commas (<code>,</code>) to separate values (although other characters such as <code>;</code> can also be used).</p> Sink (from <code>CSV.read</code>) <p>It is the second positional argument from <code>CSV.read</code> and is used to specify where to store or materialize the parsed data from the CSV file. Most of the time you will want to set use a <code>DataFrame</code> (<code>CSV.read(&lt;filename&gt;, DataFrame)</code>)</p> Excel <p>Excel is a widely used spreadsheet program developed by Microsoft. Excel files typically have the <code>.xls</code> and <code>.xlsx</code> extensions, but the <code>.xlsx</code> extension should be preferred.</p> SAS data files <p>Data format used and created by the SAS statistical software. They come in two common extensions: <code>.sas7bdat</code> and <code>.xpt</code>. These files can be read in Julia  using the <code>ReadStatTables.jl</code> package.</p> <code>DataFrame</code> <p><code>DataFrame</code>s are a versatile and widely used data structure that represents tabular data. You can use them in Julia through the <code>DataFrames.jl</code> package.</p> <code>DataFrames.jl</code> <p>Julia package that allows working with <code>DataFrames</code> in Julia. It has a similar design and functionality to other well-known packages such as  <code>pandas</code> from Python or <code>dplyr</code> from R.</p> <code>DataFramesMeta.jl</code> <p>A powerful package in Julia that extends the functionality of <code>DataFrames.jl</code>, enabling advanced data manipulation and transformation.  It provides a concise and expressive syntax for defining data transformations through the use of macros.</p>"},{"location":"reference/#get-in-touch","title":"Get in touch","text":"<p>If you have any suggestions or want to get in touch with our education team, please send an email to training@pumas.ai.</p>"},{"location":"reference/#license","title":"License","text":"<p>This content is licensed under Creative Commons Attribution-ShareAlike 4.0 International.</p> <p></p>"},{"location":"waiver/","title":"Waiver of Liability for Pumas-AI Data Wrangling Workshop","text":"<p>By using the content provided by Pumas-AI, you agree to the following:</p> <ol> <li>You acknowledge that Pumas-AI has provided you with access to certain content (the \"Content\"),    including but not limited to software, documentation, images, videos, and other materials.</li> <li>You understand and agree that the Content is provided \"as is,\" without warranty of any kind,    either express or implied, including but not limited to the implied warranties of merchantability    and fitness for a particular purpose.</li> <li>You acknowledge that Pumas-AI is not responsible for how you use the Content,    and that Pumas-AI shall not be liable for any damages arising from your use of the Content,    including but not limited to direct, indirect, incidental, special, consequential, or punitive damages,    whether in an action of contract, negligence, or other tortious action,    even if Pumas-AI has been advised of the possibility of such damages.</li> <li>You agree to indemnify, defend, and hold harmless Pumas-AI, its officers, directors, employees, agents,    and affiliates from and against any and all claims, damages, losses, liabilities,    and expenses (including reasonable attorneys' fees) arising from your use of the Content.</li> <li>You acknowledge that this Waiver of Liability is a legally binding agreement between you and Pumas-AI,    and that it governs your use of the Content.    If you do not agree to the terms of this Waiver of Liability, you must immediately cease using the Content.</li> </ol>"},{"location":"waiver/#get-in-touch","title":"Get in touch","text":"<p>If you have any suggestions or want to get in touch with our education team, please send an email to training@pumas.ai.</p>"},{"location":"waiver/#license","title":"License","text":"<p>This content is licensed under Creative Commons Attribution-ShareAlike 4.0 International.</p> <p></p>"}]}